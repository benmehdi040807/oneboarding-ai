// app/api/generate/route.ts
import { NextResponse } from "next/server";

export const runtime = "edge"; // rapide et compatible Vercel

type Body = { prompt?: string; locale?: string };

function mockAnswer(prompt: string) {
  return [
    `üéØ *Interpr√©tation rapide* : ${prompt}`,
    ``,
    `‚úÖ *Proposition concr√®te* :`,
    `- √âtape 1 : ...`,
    `- √âtape 2 : ...`,
    `- √âtape 3 : ...`,
    ``,
    `‚úçÔ∏è Texte pr√™t √† copier :`,
    `> Votre brouillon personnalis√© pour ¬´ ${prompt} ¬ª.`,
  ].join("\n");
}

export async function POST(req: Request) {
  try {
    const { prompt = "", locale } = (await req.json()) as Body;

    if (!prompt.trim()) {
      return NextResponse.json(
        { ok: false, error: "Aucun texte fourni." },
        { status: 400 }
      );
    }

    // Mode d√©mo si pas de cl√© (ou si MOCK_OPENAI=1)
    const noKey = !process.env.OPENAI_API_KEY;
    const useMock = process.env.MOCK_OPENAI === "1" || noKey;

    if (useMock) {
      return NextResponse.json({
        ok: true,
        output: mockAnswer(prompt),
        mock: true,
      });
    }

    // Appel OpenAI (chat.completions pour compatibilit√© large)
    const res = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini", // rapide/√©co, rempla√ßable par un autre mod√®le
        temperature: 0.7,
        max_tokens: 600,
        messages: [
          {
            role: "system",
            content:
              "Tu es OneBoarding AI. Donne une r√©ponse utile, concise et actionnable, en fran√ßais si la demande est en fran√ßais. Formate en markdown simple.",
          },
          {
            role: "user",
            content: locale ? `[lang=${locale}] ${prompt}` : prompt,
          },
        ],
      }),
    });

    if (!res.ok) {
      const txt = await res.text();
      return NextResponse.json(
        { ok: false, error: `OpenAI error: ${txt}` },
        { status: 500 }
      );
    }

    const data = await res.json();
    const output =
      data?.choices?.[0]?.message?.content?.trim() ??
      "D√©sol√©, aucun texte re√ßu.";

    return NextResponse.json({ ok: true, output });
  } catch (err: any) {
    return NextResponse.json(
      { ok: false, error: err?.message ?? "Erreur interne." },
      { status: 500 }
    );
  }
}
